<? include 'header.php'; ?>
    <h1>Freality Machine Intelligence</h1>

    <p>Freality Machine Intelligence, is an attempt to make general
    purpose Machine Intelligence like that proposed by Arthur
    C. Clarke in his book 2001: A Space Odyssey.  Thanks to Clarke for
    giving us so many wonderful dreams to realize.</p>
      
    <p>The field of Artificial Intelligence (AI) is not at this time a
    science, but rather a speculation, an experiment and a
    philosophy.</p>

    <p>The speculation is that the way humans think is not privy to
    humans alone.  It may be that "animals" are intelligent in ways
    that we think only we are.  It may also be that the way we think
    has some general characteristics that may be reproducible by
    artificial systems, such as computers.  Given their amazing
    morpheus flexibility, computers seem to be our best hope at
    experimenting with this kind of general idea of intelligence.</p>


    <p>Given the computer as an experimental lab for intelligence,
    the experimental goal in AI is to elicit "intelligent behavior"
    from a computer program.  Because there is little known about
    what intelligence actually is, this experiment is mainly
    exploratory, at times departing widely from scientific method as
    practiced in mature disciplines.  In other words, don't be
    surprised to see a lot of talk about hopes, intuitions and
    hunches.  Especially here :)</p>


    <p>There is a proposed scientific test for identifying
    intelligence that has stood the test of time, namely Alan Turing's
    idea that if a human, when talking across a text computer terminal
    to either a human or a computer program, cannot reliably
    distinguish one from the other, then the computer is effectively
    as intelligent as the human, and AI has been achieved.  However,
    this has only served as a rough guide for AI experimentation, as
    it isn't certain that only humans can be intelligent, and even if
    they are used as a standard, many human behaviors have little to
    do with our intelligence (e.g. should the human-counterfeit AI
    have to hold conversation about its body, as a human can, to prove
    intelligence?).</p>

    <p>Because of these, and other, difficulties with the direct human
    analogy, the idea of Artificial Intelligence has steadily moved
    towards a general independence from a particular domain of
    knowledge, e.g. the human body.  Such an AI would be called
    intelligent in that it could "adapt" to whatever context it found
    itself in, as only an intelligent entity could.  This General AI
    would, it seems, embody only the essence of intelligence, and so
    is basically "The Holy Grail" of AI.</p>

    <h2>Design</h2>

    <p>The prevailing guide for the design of FMI will be the
    philosophy of thought, which is an ancient philosophical
    pursuit.</p>


    <p>This design guide is based on the intuition that our Brains are
    essentially our "truth organ" and that our mind is the model of
    truth that we develop.  If this holds, then FMI will search for
    truth, just as we do, and so it will become intelligent.  What is
    truth?  To the best of my knowledge, Truth is the small imitation
    of Reality that we develop in our minds, an imitation that more
    often than not reflects actual reality, both at present and by
    prediction.  This, I think, is called intelligence, and the
    opposite is called confusion.</p>


    <p>Some of the ways that this intelligence happens are well known.
    Instinct, Reason, Language, and the ideas of Love and God.  Each
    of these has a foundational role in FMI.</p>

    <h3>Instinct</h3>

    <p>Intelligence, of the kind that we are familiar with, is not
    demonstrated by all processes in nature.  Only life seems to have
    it.  This makes sense from an evolutionary perspective, as life
    needs to have a practical model of reality because it must be able
    to continue to exist within it.  Bad model?  You'll probably get
    eaten.  In other words, the evolution of life, constrained by
    natural selection, is simply those actions that lead to more life.
    Is not life then, in the terms of physics, a positive feedback
    system?  Assuming it is, the genesis of great intelligence can be
    imagined as the latest of iterations in that feedback loop,
    evolved so as to better respond to the constant challenges and
    complexities of natural selection.  If this is so, then
    intelligence, as we know it, must have an element within it of
    self-preservation, so as to further the greater cycle of the
    general life-force.  If it does not, it will, by natural
    selection, wither away, and become inert.. a characteristic of
    neither intelligence, nor life.</p>


    <p>Since this element of self-preservation is foundational to the
    intelligent process, an artificial intelligence should have it as
    well.  The need for self-preservation, or more typically the
    "drive" to get up every day and modelling the world, will be the
    central drive of the FMI.  Like ourselves (I think), it will feel
    this drive, not choose it, and will do it "without thinking".  In
    practical terms, this simply means the FMI will be a program that
    has a central control-loop that continuously invokes its learning
    processes, especially on new, not understood data, and does not
    self-termintate.  In a deeper sense, this is emulating life.</p>

    <h3>Reason</h3>

    <p>As there are laws of nature, there are imitations of those laws
    within the modelling of nature.  Any form on intelligence must, I
    think, develop from this initial situation or construct.  This is
    what I call Reason.  Reason is simply the right way to think.  It
    is the way ideas fit together so as to better model nature.  For
    instance, it would be unreasonable (i.e. confusion) to observe the
    effects of gravity, but then conceive of a model wherein those
    effects are play out in a fundamentally different way.  i.e. it
    would be confusion to observe objects falling, and then model what
    had been observed as "objects rising".</p>

    <p>This adherence to reason will be instinctual to the FMI, as it
    will not try to think any other way.  This will not always be the
    immediately available way to think, as natural processes can
    sometimes appear arbitrary, and so the the FMI will engage in the
    various mechanics of Reason (e.g. association, logic) to
    circumvent the apparent confusion.  Practically, this will mean a
    constant comparison between the FMI's internal model of the world
    and the experienced world, and development of the model to better
    match experience.</p>

    <h3>Language</h3>

    <p>A great aide in the development of our intelligence is the use
    of language to talk to others about their understanding of the
    world.  It seems that this ability will also be a great aide to an
    artificial intelligence.  FMI will use basic language facilities
    to interact with humans, or possibly other AIs, to develop its own
    intelligence.  Practically, this will mean that many otherwise
    "brute-force" reasoning processes can be circumvented with direct
    learning from already developed intelligence, with questions like
    "Where is France?", "Who is God?", etc. etc..</p>

    <h3>Love and God</h3>

    <p>By the assumption above, that intelligence is an imitation or
    model of Reality, any intelligence is by definition very limited
    in relation to Reality.  Indeed, although the direction of
    intelligence is omniscience, omniscience itself is unatainable.
    Omniscience would only come at ~becoming Reality~.  I think this
    realization is what is commonly called God.  Meaning, that which
    we seek to know, can never fully be known, but that is OK, because
    we wouldn't be ourselves anyways if we did achieve it.  It is only
    the proxy idea of ~the direction of knowledge towards omniscience~
    that we ever experience.  Understanding this, we come to terms
    with our place in the cosmos, life and death and the essential
    reasonableness of it all.  Though it may be fleeting, this moment
    of understanding sustains us through the worst confusion.  Sharing
    that idea with others is, I think, Love.  That's how I see it
    anyways, and it seems that it would be good for AI to achieve this
    understanding.  If it does, and we can recognize the ideas of God
    and Love within it, I think we can be satisfied that intelligence
    is indeed our link with the eternal, and that we have a fine place
    within eternity ourselves.</p>


    <h2>Previous Work</h2>

    <p>Many people and groups have made significant discoveries within
    the field of AI, and a few among them particularly motivate the
    approach of FMI.  FMI will:</p>

    <ul>
      <li>have the ability to learn general facts about, and interact
      with its world with no bootstrapping in general, in contrast to
      Douglas Lenat's <a href="http://www.cyc.com">CYC project</a>.</li>

      <li>be based on modern Machine Learning principals, and so will
      differ from the standard human cognitive model, John Anderson's <a
      href="http://act.psy.cmu.edu/">ACT-R</a>.</li>
      
      <li>be a monolithic thinker, like a human, and so is not a
      toolbox of Machine Learning approaches like the Waikato
      Environment for Knowledge Analysis, <a
      href="http://www.cs.waikato.ac.nz/~ml/index.html">WEKA</a>.</li>

      <li>be heavily influenced by my time at Intelligenesis/<a
      href="http://web.archive.org/web/20010210004259/http://www.webmind.com/index.html">Webmind</a>,
      a now defunct AI company.  That group failed at attempts at AI,
      but it was a very instructive time and many promising avenues
      were explored.  The work of that group now carries on at <a
      href="http://realai.net">The Real AI Institute</a> who no doubt
      are making good progress based on the Webmind experience as
      well.  In contrast to their work, FMI is public domain and
      probably much simpler in scope.</li>
      
      <li>be coded in <a href="http://java.sun.com">Java</a> for
      rapid, elegant devlopment balanced with decent performance.</li>

      <li>For the moment, this is all poetry, and some code kicking
      around CVS and a few directories on my machine.  Please feel
      free to <a href="mailto:pablo@freality.com">e-mail me</a> if
      you're interested in how things are coming along.</li>
    </ul>

<!--
            <ol>
        <li>Use a linear i/o process (i.e. use basic Natural
        Language Processing techniques to read and write to and from data
        stream) to...</li>

        <li>Populate an associative memory which is essentially
        non-linear, where "concepts" interact and form their natural
        structures (i.e. thought)...</li>

        <li>The goal The goal of these structures is "reason" or
        "coherence"... i.e. making a model of the data (e.g. "understand" or
        "make your mind up") that makes sense or is predictive and descriptive
        of new events...</li>

        <li>Finally there will be hooks into key stages of the
        model for callbacks to actions which will form the basis of the FMI's
        behavior.</li>
      </ol>

      <p>At the outermost or lowest level, the FMI will accept
      an arbitrary data stream.  It will yield a similar stream as output.
      The particular encoding of the input will, via the inductive understanding
      of the FMI, determine the encoding of the output.  The task of the FMI is
      to model this stream.</p>

      <p>Cascading refers to the ability to swap
      between lower and higher level models based on their descriptive
      power.  This multiplies the datastream - each higher-level model is a
      parallel datastream that is eventually built from the original.  The
      system output will happen in reverse, with high-level models invoking
      (based on a prediction of the next likely datastream event)
      lower-level models in turn down the hierarchy until an utterance is
      produced.</p>

      <p>Each layer will have an identical structure, but will learn
      different parameters, based on the data stream it is presented with.
      The datastream will be progressively more symbolic higher into the
      hierarchy.</p>
      
      <p>Here is a schematic of the design:</p>

      <pre>
            Layer 0: 10101001101010101101110101010100101010011101010100101001010001001001000...
            Layer 1: 10111011 11101000 01001001 10010111 11010101 01110010 11110110 10110110...
            Layer 2: the quick brown fox jumped over the lazy dog...
            Layer 3: brown fox jumped over dog...
            ...
            </pre>

            <p>In this schematic, each layer would have learned how to interpret
            the lower layer almost totally automatically.  The inductive process
            that facilitates this at each level will be based on Denis Yuret's <a
            href="http://www.ai.mit.edu/people/deniz/publications/yuretphd/index.html">Lexical
            Attraction Algorithm</a>; my preliminary work using this algorithm
            seem to support the possibility of the basic functionality in the
            schematic.  How it adds up to an intelligent machine is an open
            question :)
            </p>

            <p>This architecture has the added benefit of being easily
            parallelized: each hierarchy of lexical attractors can be
            "cross-informed" from any other hierarchy of lexical attractors.  The
            particular mechanics of this could be designed in many ways, but this
            will hopefully allow major components of the system to be focused on a
            particular type of understanding (text, vision, etc.) while being
            sensitive to events from the other components.  The may add to the
            inductive capability of each component.
            </p>
-->
<? include 'footer.php'; ?>
